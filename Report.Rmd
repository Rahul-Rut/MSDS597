---
title: "Report"
output: 
  html_document:
    theme: flatly
runtime: shiny #makes it a shiny document! 
  
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(rvest)
library(jsonlite)
library(httr) 
library(curl) 
library(stringr)
library(RCurl)
library(tibble)
library(lubridate)
library(shiny)
library(dplyr)
library(purrr)
library(ggplot2)
library(tidyr)
library(tidyverse)


options(dplyr.summarise.inform = FALSE) #This disables messages that cannot be categorized as warnings
```

## Introduction

The purpose of this project is to investigate music trends using the Spotify Charts website. We wanted to explore the top Spotify artists and genres over a specific period of time. This report outlines our process, from scraping the data from the website, cleaning the data, creating functions to analyze the data, to an interactive Shiny app. In addition, we used the Spotify API to help generate the genre for the top tracks as that is not included in the charts.

## Initial Exploration

The first thing we must do is bring the data into R. We do so by scraping the table from the Spotify Charts website.
The url used in this section of the report opens the Top 200 Songs globally for the week of April 8th - April 15th 2022.

Initially, our data only shows the title of the track and the number of streams. We need to find a way to add the artists to this data.

```{r Scrape, echo=FALSE}
#Specify the link
url <- "https://spotifycharts.com/regional/global/weekly/2022-04-08--2022-04-15"
#Extract the table
table <- url %>% read_html() %>% html_table(fill = TRUE) %>% .[[1]] 
names(table)[1] <- "a"
names(table)[2] <- "Number"  #name the unnamed columns so we can convert to tibble
names(table)[3] <- "b"
table <- as_tibble(table) %>% select(Number,Track,Streams)
head(table,6)
# This gives us the title of the track and number of streams, but doesn't list the artist!
```

To add an artist column, we can use Selector Gadget to find the specific node id for artists. We extract the artists from the site as a column and append it to our data. 

```{r Artists, echo=FALSE}
artists <- url %>% read_html() %>% html_nodes("span") %>% html_text2() 
artists_list <- artists[2:201] %>% as_tibble() %>% rename(Artist=value) #create a list of the artists for the given chart
#Now we can clean the list by removing the "by" in every entry, leaving only the artist
artists_list$Artist <- str_replace_all(artists_list$Artist,"by ","")
#Add the artists to the original table
table <- mutate(table,Artist = artists_list$Artist)
head(table,6)
```

The next step is to clean the data. We still have a new line and the artist name in the track title, and streams are recorded as characters, not integers. Once we remedy this, we have our final data.

```{r Clean, echo=FALSE}
#Fix the track names
table$Track <- str_replace_all(table$Track, "(?<=by).+","") #Get rid of everything preceded by "by"
table$Track <- str_replace_all(table$Track, "by","") #Get rid of "by"
table$Track <- trimws(table$Track,"right") #Get rid of trailing white space
#Convert streams to numbers
table$Streams <- str_replace_all(table$Streams,"[,+]", "")
table$Streams <- as.integer(table$Streams)
head(table,6)
```

Now we can create some basic visualizations. The first thing we wanted to see was the top tracks for the week. 

```{r Top Tracks, echo=FALSE}
top <- table %>% mutate(Track=reorder(Track,Streams)) %>% head(10)
ggplot(top) + geom_col(aes(Streams,Track)) + ggtitle("Top Tracks This Week")
```

We see that As It Was by Harry Styles is extremely popular this week!

Next we can explore the number of hits artists have had chart this week.

```{r Number of Hits, echo=FALSE}
topartists <- table %>% group_by(Artist) %>% summarise(n=n()) %>% mutate(Artist=reorder(Artist,n)) %>% filter(n>1)
ggplot(topartists) + geom_col(aes(n,Artist)) + ggtitle("Top Artists This Week") + xlab("Number of Songs")
```

Olivia Rodrigo was extremely popular, with 7 songs on the Top 200 this week.

```{r Function, echo=FALSE}

#Note: the previous chunks have been modified to an extent and will now be used as a function to retrieve scraped data!

#Function for scraping the entire data
getSpotifyCharts <- function(url, month_bin = 0){   #month_bin, when 1, reduces the amount of data read to 50, rather than usual 200
  #we do this to reduce the amount of data stored for longer time frames
  
  #Extract the table
  table <- url %>% read_html() %>% html_table(fill = TRUE) %>% .[[1]] 
  
  if(month_bin == 1){
    
    table <-table[1:50,]  #reading only first 50 entries
  }
  
  
  names(table)[1] <- "a"
  names(table)[2] <- "Number"  #name the unnamed columns so we can convert to tibble
  names(table)[3] <- "b"
  table <- as_tibble(table) %>% select(Number,Track,Streams)
  
  #Try using Selector Gadget
  artists <- url %>% read_html() %>% html_nodes("span") %>% html_text2() 
  artists[2] #This is where the artists start being listed
  artists_list <- artists[2:201] %>% as_tibble() %>% rename(Artist=value) #create a list of the artists for the given chart
  
  
  if(month_bin == 1){
    artists_list <- artists_list[1:50,]  #reading just the first 50 again
  }
  
  
  #Now we can clean the list by removing the "by" in every entry, leaving only the artist
  artists_list$Artist <- str_replace_all(artists_list$Artist,"by ","")
  table <- mutate(table,Artist = artists_list$Artist)
  
  table$Track <- str_replace_all(table$Track, "(?<=by).+","") #Get rid of everything preceded by "by"
  table$Track <- str_replace_all(table$Track, "by","") #Get rid of "by"
  table$Track <- trimws(table$Track,"right")
  
  table$Streams <- str_replace_all(table$Streams,"[,+]", "")
  table$Streams <- as.integer(table$Streams)
  table         #returning table
  
  
}

```




## Using Spotify API to add Genre


As seen, the charts are limited to Songs, their Artists and the number of Streams. So, here we add "genre" for each song by accessing the Spotify API. 


### Before we proceed, let's explain HOW the Spotify API works. 

The Spotify API has various Endpoints like "Get Artist", "Get Album", "Search Item" etc. which return the resources we need, when received a "GET" request from the User. 

This GET request requires Authorization in the form of Access tokens, which in turn can be generated by a specific set of Client ID and Secret provided to Spotify Users after registration. 

However, these tokens have a lifespan of 60 minutes so we need to regenerate them before using them.



This is how a RESPONSE from one such Endpoint (Get Artist) looks like:
```{r API, echo=FALSE}
#Generating API Token

#The use of Spotify API requires Client Credentials which are provided as follows
client_id <- 'redacted'
client_secret <- 'redacted'

#The way this works is that the credentials (formatted as <id>:<secret>) have to be base64 encoded
enc_str = base64(paste0(client_id,":",client_secret))  

#The encoded string then has to include a prefix of "Basic" and later used as a value in Authorization Header of the CURL POST request
auth_str = paste0("Basic ", enc_str)


#Unfortunately, GitHub wouldn't let me upload the Spotify Credentials due to Privacy Threat, so I have stored the entire encoded string as follows
#Although, GitHub did raise a red flag again (which shows how powerful their system is!) but I let it slide for the sake of project
auth_str = "Basic MWFkYTQwNDFiMGJkNDgyZWE0MjEyY2ZiMGIyNDYxODg6MWYzNjYwMTQyZjBjNDM4Mjg1M2E2MGY1YTZhZjU0MzU="
#this is how the string looks like after encoding

#Function for generating token
genToken <- function(){
  
  #The Following is a CURL POST request wherein we send client credentials, type of request and fetch the Access Token Required for Acessing Endpoints of API
  #The headers have been added as per the guidelines of API, where grant_type specifies the "Client Credentials Flow" aka server to server communication
  
  test_response2 = content(POST(url = "https://accounts.spotify.com/api/token", add_headers("Authorization" = auth_str) ,body = list(grant_type = "client_credentials"), encode = "form" ))
  token = test_response2$access_token  #returns the "access_token" part of the POST response
}

token = genToken()

#Demonstrating a GET Request to "Get Artist" Endpoint
artist = GET("https://api.spotify.com/v1/artists/3pc0bOVB5whxmD50W79wwO",add_headers("Content-Type"="application/json", "Authorization" = paste("Bearer", token) ))

content(artist)$genres
```


### Adding Genre

Spotify doesn't store a "genre" of a song explicitly so we can search the song from the API, get the relevant Album the song is a part of, and then extract the genre. This approach is tedious and faces other issues like not having an album allotted to the songs at all. 

Instead, we search for Genres the Artist of the song is related to. Accessing the Genre from "Get Artist" endpoint would require a Spotify ID defined Artist ID for each Artist on that platform, with no feasible way of accessing them, besides performing a hard search on Google, opening the respective Artist's Spotify Page and then extracting the last few characters from the URL! 

So, we use the "Search Item" endpoint, where it is possible to search for Artists by their names (as provided in the chart!) and get the Genres there itself. This, however, assumes that no Artist Name is repeated.

To sum it up, from the Scraped Data, we will pass the Artists' Names to the Search Item endpoint of Spotify API and retrieve the Genre for the best matched Artist!


An instance, after adding genres and splitting/unnest-ing the same (since genres are stored as lists) looks as follows:


```{r Genre, echo=FALSE}

#This function fetches Genre of a given Artist from Spotify API and passes onto the "getGenreTibble" Function

getGenreArtist <- function(artist, token){  #accepts URL ecnoded Artist Name and Token as parameter
  
  #Try Catch is to negate null values or Artists with No Genre which is rare!
  tryCatch(  {search = GET(paste0("https://api.spotify.com/v1/search?q=", artist ,"&type=artist&limit=1"),add_headers("Content-Type"="application/json", "Authorization" = paste("Bearer", token) ))
  
  #Lets break down the above code line
  #The "search?q=" signifies that we are using the "search item" endpoint, followed by artist name
  # the "&type=artist&limit=1" means we are searching for an Artist, not a song, and limiting our results to the Top 1 search
  #the reason we are comfortable with limiting the search to 1 is that the Artists Name are generated by Spotify itself and hence we are bound to get perfect match
  #second of all, these Artists will be searched from the TOP 200 CHARTS meaning they ought to be famous, and hence will be fetched first in case of name clashes
  #we pass the token in the authorization header, and the rest is basic CURL format as specified by the Spotify API
  
  
  result = content(search)  #the results are stored using the content function
  result = result$artists$items[[1]]$genres}, error = function(e){})  
  
  #we retrieve the "$genres" of artist and return it to the user
  
  

  
}



#This function generates Genres for a given Data Entry (aka Genres For a Song)
#The approach here is that many songs have multiple artists, and one approach to save genre is without splitting the entry per artist, we find the genres of the song

getGenreTibble <- function(artistS, token){   #takes artists and access token as parameter
  url_encoded = URLencode(artistS)            #modifying artists' name to URL format
  genres = unique(unlist((map2(url_encoded, token ,getGenreArtist))))    #mapping the encoded artist name and token to generate artist function
  #'unlist' helps us unpack or flatten the list and 'unique' function gets rid of common genres between artists of a same song 
  
}

table%>%
    mutate(Artist_sing = (str_split(Artist, ", ")))%>%   #splits the artists in a tibble for a given song
    mutate(Genres = map2(Artist_sing, token, getGenreTibble))%>%  #call previously defined funcitons 
    select(Number, Track, Artist, Genres)%>%
    unnest(Genres)%>%
    head(6)


```


## Expanding our Scraping

The Top Charts displayed can be modified for two parameters: Region and Time (Daily and Weekly).


The typical URL looks as follows: 

"https://spotifycharts.com/regional/global/daily/latest"

As seen above, the "global" part in URL determines region, and can be substituted for various other regions like USA, UK or many others. Similarly, the "daily" part can be altered with "weekly", fetching results for the latest week.

But that isn't all there is to the time frame! Charts from older days and weeks can be fetched as well:

"https://spotifycharts.com/regional/global/weekly/2022-04-22--2022-04-29"

Above is one such example wherein an older week's chart was retrieved using the URL above.

Now that we know that we can acquire older data by modifying the URL, we will do so and generate Monthly Data (assuming 4 previous weeks constitute a month) and Yearly data (assuming 48 weeks form a year).




Following is how the generated dates range for weekly URL look like:


```{r Date, echo=FALSE}
date1 = "2022-04-01" #A reference date used to generate weekly dates

#As it will be seen further, the "Weekly" Data will be used to generate Weekly, Monthly as well as Yearly Data.
#But alas! The Weekly Data in Spotify Charts is calculated between 2 consecutive Fridays, rather than 7 days before the current date.
#These dates are passed in the URL for Spotify charts 
#Besides the current week (which CAN also like "/weekly/latest") the other Weekly Charts follow "weekly/2022-04-15--2022-04-22" format in their URL
#Hence, to calculate the last Friday Date, or rather, generate proper weekly dates, we will be using this "date1" as reference and the following function


getWeeks <- function(week1_date, n =1) {   #calculates 1 week prior date range (default); n is number of past weeks
  todate = today()                         #get today's date using lubridate's today function
  offset = (interval(date1, todate)/ days (1)) %% 7   #offset stores the days between today and the closest week range suitable for Spotify
  if (offset!= 0){       #if offset exists
    todate = todate - offset    #update the date to the nearest week range
  }
  
  #this step calculates all the dates required in the weeks list where n decides number of weeks and stores in vector
  dates = todate - (7 * (seq(0,n)))  
  #for example, if one wants to fetch dates for past two weeks (n=2), then this function produces 3 dates
  #assuming today is 15th April, the dates produced are 2022-04-15, 2022-04-08, 2022-04-01
  
  
  #the next line concatenates them in string type suitable to be used by URL
  weeks = paste0(dates[-1] ,"--",dates[-length(dates)]) 
  #continuing previous example, dates[-1] would drop first date and store 2022-04-08, 2022-04-01 whereas dates[-length(dates)] would drop last date and store 2022-04-15, 2022-04-08
  #hence, pasting these with "--" in between gives us "2022-04-08--2022-04-15" and "2022-04-01--2022-04-08" which is exactly what we need in the url!
  
  return(weeks)
}


getWeeks(date1, 4)
```


These can then, along with the Regions, be appended to the URL and be used to retrieve Scraped Data for various combinations.


## Shiny Application


Using the previously defined functions up until now, we will integrate them all in a Shiny Application which dynamically displays two plots : Top Genres and Top Artists for a specific Region and Time Frame.


Disclaimer: Generating Plots takes some time since scraping, and running several API requests (the same number as artists present in the chart) happens in real time which can cause some delay. This is done in order to fetch real data and make this application dynamic in nature! So, it is requested that you do not spam the "Generate Plots" button, and patiently wait.

```{r Plots, echo = FALSE}

#The following lines of code are specific for the app

date1 = "2022-04-01"  #storing the date1


#This list corresponds to the list available in the dropdown in App
country_list = c("Global", "USA", "UK", "Australia", "Brazil", "Canada")

#This list corresponds to the above list's codes as used in Spotify URL
code_list = c("global","us","gb","au","br","ca")

#a tibble that stores the bith the above lists side by side
concode = tibble(country_list, code_list)


#The following functions translates the button inputs from app to URL format required suffix

#A function used to fetch the Country's codes from their Names using the previous Tibble
matchRegion <- function(region){
  concode%>%
    filter(country_list == region)%>%  #matching the region
    select(code_list)    #fetching just the codes
}



#This function translates the output of "Time" button from shiny app to suitable format for URL search
getDates<- function(time_period){
  
  #just used if else loop 
  if (time_period == "Monthly")
  {
    dates = getWeeks(date1, n = 4)
    suffix = paste0("/weekly/",dates)
  }
  else if (time_period == "Daily")
  {
    return (c("/daily/latest/"))
  }
  else if (time_period == "Weekly")
  {
    return (c("/weekly/latest/"))
  }
}


#After translating the codes, we append them to url and get scraped data
getScraped <- function(region,dates){
  URL = paste0("https://spotifycharts.com/regional/",region,dates)
  if (length(URL) == 1){  #this is for weekly, daily since we will be scraping just once
    getSpotifyCharts(URL)
    
  }
  else {
    
    #for monthly we have to scrap several times hence we use map
    #the "1" is month_bin parameter which enables reading only top 50 entries to reduce size of data stored
    month_list = map2( URL,1, getSpotifyCharts)   
    month_scraped =  month_list%>%
      bind_rows(.) #binding all the weekly data into 1 monthly data
  }
}


#This function is called by shiny app to generate plots
main <- function(region, time_period, plot_type){   #accepts input from shiny app aka desired time period and region 
  

  region_code = matchRegion(region) #translating region to code that fits with url for
  
  dates = getDates(time_period) #translating time period to code that fits with url
  
  scraped = getScraped(region_code,dates)  #getting scraped data
  
  token = genToken()  #generating access token
  
  #this generates plot for TOP ARTISTS in given time frame and region
  
  if (plot_type == "art"){
  art_plot <- scraped%>%  
    separate_rows(Artist, sep = ",", convert = TRUE)%>% #splits Multiple Artists, if any, in multiple rows (much like pivot_longer!)
    group_by(Artist)%>%                      #grouping by artist
    summarize(Total_Stream = sum(Streams))%>%   #Finding total streams per artist
    arrange(desc(Total_Stream))%>%              #Arranging them in descending order
    head(10)%>%                                 #storing just the TOP 10 Artists
    mutate(Artist=reorder(Artist,Total_Stream))%>%   #Reordering Artists as per their order of Streams
    ggplot()+ 
    geom_col(aes(Total_Stream/1000000,Artist)) +      #plotting Total Streams
    ggtitle(paste("Top Artists", time_period ,region))+  #finishing touch
    labs(x="Total_Streams(in Millions)", y= "Genre")
  return(art_plot)
  }
  
  else if (plot_type == "gen"){
#This Generates plot for TOP GENRES in given time and region
  genplot <- scraped%>%
    mutate(Artist_sing = (str_split(Artist, ", ")))%>%   #splits the artists in a tibble for a given song
    mutate(Genres = map2(Artist_sing, token, getGenreTibble))%>%  #get genre per song
    unnest(Genres)%>%     #splits every genre into each row (more like pivot longer)
    group_by(Genres)%>%   #groups by genre
    summarise(Total_Streams = sum(Streams))%>%   #calculates total streams per genre
    arrange(desc(Total_Streams))%>%    #arrange into descending order per total streams
    head(10)%>%                        #store just the top 10
    ggplot(aes(Total_Streams/1000000, reorder(Genres, Total_Streams)))+   #plot top 10 genres
    geom_col()+
    labs(x="Total_Streams(in Millions)", y= "Genre", title = paste("Top Genres",time_period ,region))
  return(genplot)
  }
  
  
  #a function to generate dates
  #scrape
  #get genre
  #plot genre, artist
  
}
```


```{r Shiny, echo = FALSE}

region_choices = c("Global", "USA", "UK", "Australia", "Brazil", "Canada") #used in dropdown for region
library(shiny)


shinyApp(ui = fluidPage(
  sidebarLayout(   #defining side bar 
    sidebarPanel(    #sidebar panel
      selectInput("region", "Select Region", choices = region_choices ),  #Defining dropdown with choices
      selectInput("time", "Select Time", choices = c("Daily","Weekly", "Monthly")),  #same as last but for time
      actionButton("go", "Generate Plots")),  #a button, which when pressed, prints the plots! Think of it as buffer
    mainPanel(  #main panel for output
      plotOutput("plot"),    #plotting plot 1
      plotOutput("plot2"))   #plotting for plot 2
  )
),


server = function(input, output, session) {
  
  v <- reactiveValues(doText = FALSE)   #this will be used to store reactive value or keep checking whether a button was pressed or not
  
  observeEvent(input$go, {  #we observe changes in the button "Generate Plots" since "go" is id for that button

    v$doText <- input$go    #and store its output in the reactive value!
  })

  
  output$plot <- renderPlot({   #need render plot to, well, render plots!
    if (v$doText == FALSE) return()   #do nothing if the "Plot" button has not been touched
    
    
    isolate({main(input$region, input$time, "art")})   #but when it is pressed by the user, run the "main" function whose return value is a ggplot object andd hence can be printed!
  })
  
  output$plot2 <- renderPlot({   #same but for the other plot!
    
    if (v$doText == FALSE) return() 
    isolate({main(input$region, input$time, "gen")})
    
  })
}
)

```


### Note: Be sure to close the shiny tab WHILE running chunk wise. Otherwise the RStudio gets stuck "Listening on http://127.0.0.1:7302". Other way to escape the same is by hitting the escape key in the console tab



## Finding Top Artists and Genres Trends in the Past Year


Here, we plot the Top 10 Artists for the previous year, and see how many streams they had per month for that year.

Note: This Plot doesn't show the Top 10 Artists in 2021, rather it calculates trends back in the Past Year, starting our count from today or current week itself. Hence, Month 12 denotes the latest 4 weeks (assumed to be Month) and not December, per se.
```{r Year, echo = FALSE, warning=FALSE}
#lets make a separate dataframe for yearly scraped data @_@

weeks = getWeeks(date1, n = 48)  #for n = 48 weeks assuming 4 weeks per month
#url is set to global weekly
url = "https://spotifycharts.com/regional/global/weekly/"
dates_weeks = paste0(url,weeks)
month_list = map2( dates_weeks,1, getSpotifyCharts) #scraping data for a year (top 50 per week)
month_index = (rep( seq(12,1,-1) , each = 200)) #calculate month backwards


#Here we apply a month index (or number) to all the months
#The way Monthly Data is calculated is by attaching 4 weekly data (each with 50 rows) in one tibble can call that month tibble
#The Math for the same is that we have assumed that each month has exactly 4 weeks, so all we need to do is append a list which looks like (1,1,1,1,2,2,2,2....) since each month index will be repeated 4 times (since that month has 4 weeks)
#Moreover, as we have seen, the dates are calculated in reverse order by the getWeeks function so the index of the month has to be in reverse order as well!
#For example, the dates are generated first for the month of April 22, then March 22 and goes all the way back.
#Hence, the monthly index will look as follows (12,12,12,12,11,11,11,11,...)


Scraped = month_list%>%
  bind_rows(.)%>%
  mutate(Month = month_index) #add month index

#See how artists did over the year  


#An inconsistency I found was that Charts had "BobHelms" although Spotify identifies him as "Booby Helms"
#So had to make this change
Scraped = Scraped%>%
  mutate(Artist = replace(Artist, Artist == "BobHelms", "Bobby Helms"))

#top10 artists
ten_artists = Scraped%>%
  separate_rows(Artist, sep = ", ", convert = TRUE)%>% #splits Artists
  group_by(Artist)%>%                                  #group by artists
  summarize(Total_Stream = sum(Streams))%>%            #Calculate total streams per artist
  arrange(desc(Total_Stream))%>%                       #save in descending
  select(Artist)%>%                                   #extract just the artists
  head(10)                                            #extract just the top 10



#top10 artists performance over the year each month
global_year_artist_plot = Scraped%>%
  separate_rows(Artist, sep = ", ", convert = TRUE)%>% 
  group_by(Artist, Month)%>%
  summarize(Total_Streams = sum(Streams))%>%
  filter(Artist %in% pull(ten_artists))%>%   #filtering just the top 10 artists previously calculated
  ggplot(aes(Month, Total_Streams/1000000, color = Artist))+
  geom_line()+
  labs(y = "Total Streams (in Millions)", x = "Month", title = "Top 10 Artists in the Past Year")

global_year_artist_plot
```





As seen, Olivia Rodrigo had a peak which dates back to last year's May.

The investigation of that month looks as follows:

``` {r Olivia, echo = FALSE, warning= FALSE}
#investigating the peak
Scraped%>%
  separate_rows(Artist, sep = ", ", convert = TRUE)%>% 
  filter(Month == 1)%>% 
  group_by(Artist)%>%
  tally()%>%
  arrange(desc(n))  #Olivia Rodrigo had several hits that month!!
```

In the tibble, the sum corresponds to the number of appearances Olivia Rodrigo had in top 50 each week of that month!

Meaning, she had a very successful month!



### Plotting the same for Genres in the Past Year

```{r Genres, echo = FALSE, warning = FALSE}
#getting top genre in the past year

#getting rid of one random blank data
Scraped = Scraped%>%  #Scraped is scraped data for past year
  mutate_all(na_if,"")

#Here we find a newer way to appprach the "Extract Genre" thing
#We extract all the unique artists first, find their genre and then make a tibble which stores both the artists and their respective genres, which will later be used to map to each song!

#extracting unique artists
Artist_list = Scraped$Artist%>%
  str_split(", ")%>%
  unlist()%>%
  unique()


#calling api and storing their respective genres
token= genToken()
genres_list = map2(URLencode(Artist_list), token, getGenreArtist)

#making a tibble out of the two lists
Artist_Genre = tibble(Artist_list, genres_list )



#a function which will do the mapping!
matchGenre <- function(artist){
  result = Artist_Genre%>%filter(Artist_list == artist)
  result$genres_list
}



tpp = Scraped%>%
  separate_rows(Artist, sep = ", ", convert = TRUE)%>%  #separating multiple artists per genre
  group_by(Artist)%>%    #grouping said artists  (done to reduce the amount of calling )
  mutate(Genre = map(Artist,matchGenre))   #using mapping function!



global_year = tpp%>%
  ungroup()%>%     #ungrouping by artists
  group_by(Track, Month)%>%       #grouping by track and month
  mutate(Genre = toString(unique(unlist(Genre))))%>%    #here we get rid of any over lapping genre
  #for example, Song XYZ can have Artist A and B, where both these artists could have same genre "pop"
  #in order to avoid multiplicity of genres, we use "unique"
  separate_rows(Genre, sep = ", ")  #separating genres


#getting top 10 genres
tr = global_year%>%
  ungroup()%>%
  group_by(Genre)%>%   #grouping by genre
  summarize(Total_Streams = sum(Streams))%>%  #tally() here would give appearances of these genres per week
  arrange(desc(Total_Streams))%>%   #arranging in descending order
  select(Genre)%>%   #selecting just genres
  head(10)           #storing top 10




global_year_genre_plot = global_year%>% 
  group_by(Genre, Month)%>% #group by genre and month
  summarize(Total_Streams = sum(Streams))%>%   #total streams
  filter(Genre %in% pull(tr))%>%               #filter by top 10 genres
  ggplot(aes(Month, Total_Streams/1000000, color = Genre))+
  geom_line()+
  labs(y = "Total Streams (in Millions)", x = "Month", title = "Top 10 Genres in the past Year") 


global_year_genre_plot
```

Many of the genres in the Top 10 are Latin based, which indicates that Spotify has an active community of Latin Listeners! But as usual, Pop genre beats the rest by a huge margin!

